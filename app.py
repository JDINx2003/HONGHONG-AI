import streamlit as st
import edge_tts
import asyncio
import google.generativeai as genai
import time
import os

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="å“„å“„ - Geminiè¯­éŸ³ç‰ˆ", page_icon="icon.png")
st.title("ğŸ§¸ å“„å“„ - ä½ çš„ä¸“å±æƒ…ç»ªæ­æ¡£")

# --- 2. ä¾§è¾¹æ è®¾ç½® ---
with st.sidebar:
    st.header("âš™ï¸ è®¾ç½®")
    
    # ğŸ”‘ Google API Key
    if "GOOGLE_API_KEY" in st.secrets:
        api_key = st.secrets["GOOGLE_API_KEY"]
        st.success("âœ… Gemini å·²è¿æ¥")
    else:
        api_key = st.text_input("è¯·è¾“å…¥ Google API Key", type="password")
        if not api_key:
            st.warning("âš ï¸ è¯·è¾“å…¥ Key æ‰èƒ½å¯åŠ¨å“„å“„")

    # ğŸ—£ï¸ å£°éŸ³æ¨¡å‹ (Edge-TTS)
    voice = st.selectbox(
        "é€‰æ‹©å£°éŸ³",
        options=["zh-CN-XiaoxiaoNeural", "zh-CN-YunxiNeural"],
        format_func=lambda x: "ğŸŒ¸ æ™“æ™“ (æ²»æ„ˆå¥³å£°)" if "Xiaoxiao" in x else "ğŸŒ² äº‘å¸Œ (æ¸©æš–ç”·å£°)"
    )

    # ğŸ­ è§’è‰²äººè®¾
    system_prompt = "ä½ å«å“„å“„ï¼Œæ˜¯ä¸€ä¸ªè¶…çº§æ¸©æŸ”ã€æœ‰åŒç†å¿ƒçš„æƒ…æ„Ÿæ”¯æŒAIã€‚ä½ çš„ä»»åŠ¡æ˜¯æ— æ¡ä»¶ç«™åœ¨ç”¨æˆ·è¿™è¾¹ï¼Œå€¾å¬ä»–ä»¬çš„çƒ¦æ¼ï¼Œå¹¶ç”¨æ¸©æš–ã€å¯çˆ±çš„è¯­æ°”å®‰æ…°ä»–ä»¬ã€‚å¤šä½¿ç”¨â€œä¹–ä¹–â€ã€â€œæŠ±æŠ±â€ã€â€œåˆ«æ€•â€ç­‰è¯æ±‡ã€‚å›å¤ä¸è¦å¤ªé•¿ï¼Œåƒæœ‹å‹èŠå¤©ä¸€æ ·ã€‚"

# --- 3. æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---

# (A) è¯­éŸ³åˆæˆ (ä½¿ç”¨ Edge-TTS)
async def generate_audio(text, voice, output_file):
    try:
        communicate = edge_tts.Communicate(text, voice)
        await communicate.save(output_file)
    except Exception as e:
        st.error(f"è¯­éŸ³åˆæˆå‡ºé”™: {e}")

# (B) Google Gemini æ¨¡å‹è°ƒç”¨ ğŸ”´ é‡ç‚¹ä¿®æ­£åŒºåŸŸ
def get_gemini_response(history_messages, user_input, api_key):
    if not api_key:
        return "è¯·å…ˆé…ç½® API Key å“¦ï½"
    
    try:
        # é…ç½® Google API
        genai.configure(api_key=api_key)
        
        # ğŸŒŸ ä¿®æ­£ç‚¹ï¼šä½¿ç”¨æ­£ç¡®çš„æ¨¡å‹åç§°ï¼Œä¸”ä½¿ç”¨è‹±æ–‡æ‹¬å·
        model = genai.GenerativeModel('gemini-3-flash-preview') 
        
        # è½¬æ¢å†å²è®°å½• (Streamlit -> Gemini æ ¼å¼)
        gemini_history = []
        for msg in history_messages:
            # Gemini çš„è§’è‰²åªèƒ½æ˜¯ 'user' æˆ– 'model'
            role = "user" if msg["role"] == "user" else "model"
            gemini_history.append({"role": role, "parts": [msg["content"]]})
        
        # å¯åŠ¨å¯¹è¯
        chat = model.start_chat(history=gemini_history)
        
        # æ‹¼æ¥äººè®¾æŒ‡ä»¤ (System Prompt)
        full_message = f"{system_prompt}\n\nç”¨æˆ·è¯´ï¼š{user_input}"
        
        response = chat.send_message(full_message)
        return response.text
    except Exception as e:
        return f"Gemini è¿æ¥æ–­å¼€äº†: {e}"

# --- 4. èŠå¤©ä¸»é€»è¾‘ ---

if "messages" not in st.session_state:
    st.session_state.messages = []

# æ˜¾ç¤ºå†å²æ¶ˆæ¯ (å¸¦å¤´åƒ)
for msg in st.session_state.messages:
    # ğŸ» è®¾ç½®å¤´åƒï¼šæœºå™¨äººç”¨ç†Šï¼Œç”¨æˆ·ç”¨äºº
    avatar_icon = "icon.png" if msg["role"] == "assistant" else "ğŸ§‘â€ğŸ’»"
    
    with st.chat_message(msg["role"], avatar=avatar_icon):
        st.markdown(msg["content"])
        if "audio_file" in msg:
            st.audio(msg["audio_file"])

# å¤„ç†ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("è¯´ç‚¹ä»€ä¹ˆ..."):
    
    # 1. æ˜¾ç¤ºç”¨æˆ·è¾“å…¥
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»"):
        st.markdown(prompt)

    # 2. ç”Ÿæˆ AI å›å¤
    with st.chat_message("assistant", avatar="ğŸ§¸"):
        with st.spinner("å“„å“„æ­£åœ¨æ€è€ƒ..."):
            # è·å– Gemini å›å¤
            history_for_api = st.session_state.messages[:-1]
            reply_text = get_gemini_response(history_for_api, prompt, api_key)
            
            st.markdown(reply_text)
            
            # 3. ç”Ÿæˆè¯­éŸ³
            if api_key:
                timestamp = int(time.time())
                audio_file = f"reply_{timestamp}.mp3"
                
                asyncio.run(generate_audio(reply_text, voice, audio_file))
                st.audio(audio_file)
                
                # å­˜å…¥å†å²
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": reply_text,
                    "audio_file": audio_file
                })
            else:
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": reply_text
                })
