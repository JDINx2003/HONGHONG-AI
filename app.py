import streamlit as st
import edge_tts
import asyncio
import google.generativeai as genai
import time
import os

# --- 1. é¡µé¢åŸºç¡€è®¾ç½® ---
st.set_page_config(page_title="å“„å“„ - AI è¯­éŸ³ä¼´ä¾£", page_icon="ğŸ§¸")
st.title("ğŸ§¸ å“„å“„ - ä½ çš„ä¸“å±æƒ…ç»ªæ­æ¡£")

# --- 2. ä¾§è¾¹æ è®¾ç½® ---
with st.sidebar:
    st.header("âš™ï¸ è®¾ç½®")
    
    # ğŸ”‘ Google API Key é…ç½®
    # ä¼˜å…ˆä» Secrets è¯»å–ï¼Œå¦‚æœæ²¡æœ‰åˆ™æ˜¾ç¤ºè¾“å…¥æ¡†
    if "GOOGLE_API_KEY" in st.secrets:
        api_key = st.secrets["GOOGLE_API_KEY"]
        st.success("âœ… å·²è¿æ¥ Google Gemini")
    else:
        api_key = st.text_input("è¯·è¾“å…¥ Google API Key", type="password")
        if not api_key:
            st.warning("âš ï¸ è¯·è¾“å…¥ Key æ‰èƒ½å¯åŠ¨å“„å“„å“¦")

    # ğŸ—£ï¸ å£°éŸ³é€‰æ‹© (åªä¿ç•™æ•ˆæœæœ€å¥½çš„ä¸¤ä¸ª)
    voice = st.selectbox(
        "é€‰æ‹©å£°éŸ³",
        options=["zh-CN-XiaoxiaoNeural", "zh-CN-YunxiNeural"],
        format_func=lambda x: "ğŸŒ¸ æ™“æ™“ (æ²»æ„ˆå¥³å£°)" if "Xiaoxiao" in x else "ğŸŒ² äº‘å¸Œ (æ¸©æš–ç”·å£°)"
    )

    # ğŸ­ è§’è‰²äººè®¾ (System Prompt)
    system_prompt = "ä½ å«å“„å“„ï¼Œæ˜¯ä¸€ä¸ªè¶…çº§æ¸©æŸ”ã€æœ‰åŒç†å¿ƒçš„æƒ…æ„Ÿæ”¯æŒAIã€‚ä½ çš„ä»»åŠ¡æ˜¯æ— æ¡ä»¶ç«™åœ¨ç”¨æˆ·è¿™è¾¹ï¼Œå€¾å¬ä»–ä»¬çš„çƒ¦æ¼ï¼Œå¹¶ç”¨æ¸©æš–ã€å¯çˆ±çš„è¯­æ°”å®‰æ…°ä»–ä»¬ã€‚å¤šä½¿ç”¨â€œä¹–ä¹–â€ã€â€œæŠ±æŠ±â€ã€â€œåˆ«æ€•â€ç­‰è¯æ±‡ã€‚å›å¤ä¸è¦å¤ªé•¿ï¼Œè¦åƒæœ‹å‹èŠå¤©ä¸€æ ·è‡ªç„¶ã€‚"

# --- 3. åŠŸèƒ½å‡½æ•° ---

# (A) è¯­éŸ³ç”Ÿæˆ (Edge-TTS)
async def generate_audio(text, voice, output_file):
    try:
        communicate = edge_tts.Communicate(text, voice)
        await communicate.save(output_file)
    except Exception as e:
        st.error(f"è¯­éŸ³åˆæˆå‡ºé”™: {e}")

# (B) Gemini æ¨¡å‹è°ƒç”¨
def get_gemini_response(history_messages, user_input, api_key):
    if not api_key:
        return "è¯·å…ˆé…ç½® API Key ä¹Ÿå°±æ˜¯ä½ çš„å¤§è„‘é“¾æ¥å¯†ç å“¦ï½"
    
    try:
        genai.configure(api_key=api_key)
        # ä½¿ç”¨ gemini-1.5-flashï¼Œé€Ÿåº¦å¿«ä¸”å…è´¹é¢åº¦é«˜ï¼Œéå¸¸é€‚åˆèŠå¤©
        model = genai.GenerativeModel('gemini-3-flash-preview')
        
        # è½¬æ¢å†å²è®°å½•æ ¼å¼ (Streamlit -> Gemini)
        gemini_history = []
        for msg in history_messages:
            role = "user" if msg["role"] == "user" else "model"
            gemini_history.append({"role": role, "parts": [msg["content"]]})
        
        # å¯åŠ¨å¯¹è¯ä¸Šä¸‹æ–‡
        chat = model.start_chat(history=gemini_history)
        
        # å‘é€å¸¦æœ‰äººè®¾æŒ‡ä»¤çš„æ¶ˆæ¯
        # æŠ€å·§ï¼šå¦‚æœæ˜¯ç¬¬ä¸€æ¬¡å¯¹è¯ï¼Œæˆ–è€…ä¸ºäº†å¼ºåŒ–äººè®¾ï¼ŒæŠŠ prompt æ‹¼åœ¨å‰é¢
        full_message = f"{system_prompt}\n\nç”¨æˆ·è¯´ï¼š{user_input}"
        
        response = chat.send_message(full_message)
        return response.text
    except Exception as e:
        return f"å“„å“„çš„å¤§è„‘è¿æ¥æ–­å¼€å•¦: {e}"

# --- 4. èŠå¤©ç•Œé¢é€»è¾‘ ---

# åˆå§‹åŒ–å†å²è®°å½•
if "messages" not in st.session_state:
    st.session_state.messages = []

# æ˜¾ç¤ºèŠå¤©å†å² (ä¿ç•™æ–‡å­—å’Œå¯¹åº”çš„è¯­éŸ³æ¡)
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        # å¦‚æœè¯¥æ¡æ¶ˆæ¯æœ‰è¯­éŸ³æ–‡ä»¶ï¼Œæ˜¾ç¤ºæ’­æ”¾å™¨
        if "audio_file" in msg:
            st.audio(msg["audio_file"])

# èŠå¤©è¾“å…¥å¤„ç†
if prompt := st.chat_input("åœ¨è¿™é‡Œå€¾è¯‰ä½ çš„å¿ƒæƒ…..."):
    
    # 1. æ˜¾ç¤ºç”¨æˆ·è¾“å…¥
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # 2. ç”Ÿæˆ AI å›å¤
    with st.chat_message("assistant"):
        # è¿™é‡Œçš„å ä½ç¬¦ä¼šæ˜¾ç¤ºåŠ è½½åŠ¨ç”»
        with st.spinner("å“„å“„æ­£åœ¨å¬..."):
            # è·å– Gemini çš„æ–‡å­—å›å¤
            # æ³¨æ„ï¼šä¼ å…¥çš„æ˜¯é™¤å»å½“å‰è¿™æ¡ä¹‹å¤–çš„å†å²ï¼Œå› ä¸º current prompt å•ç‹¬ä¼ 
            history_for_api = st.session_state.messages[:-1]
            reply_text = get_gemini_response(history_for_api, prompt, api_key)
            
            # å…ˆæ˜¾ç¤ºæ–‡å­—
            st.markdown(reply_text)
            
            # 3. ç«‹å³ç”Ÿæˆå¹¶æ’­æ”¾è¯­éŸ³
            if api_key:
                timestamp = int(time.time())
                audio_file = f"reply_{timestamp}.mp3"
                
                # è¿è¡Œå¼‚æ­¥è¯­éŸ³ç”Ÿæˆ
                asyncio.run(generate_audio(reply_text, voice, audio_file))
                
                # æ˜¾ç¤ºæ’­æ”¾å™¨ (autoplay=True åœ¨æŸäº›æµè§ˆå™¨å¯èƒ½ç”Ÿæ•ˆ)
                st.audio(audio_file)
                
                # 4. å°†å›å¤å­˜å…¥å†å² (åŒ…å«éŸ³é¢‘è·¯å¾„)
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": reply_text,
                    "audio_file": audio_file
                })
            else:
                # å¦‚æœæ²¡æœ‰ Keyï¼Œåªå­˜æ–‡å­—
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": reply_text
                })
